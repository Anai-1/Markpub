政策文本特征提取
[1]车蕾.稀疏平衡变分自动编码器的文本特征提取[J].国防科技大学学报,2022,44(01):169-178.
摘要：针对文本特征提取方面的高维数据持征区分度较低、基于规则的特征学习的自学习性能差、变分自动编码最存在过度剪校等问题，提出稀疏平衡变分自动编码器（Spare Balanced Variational AutoEncoder, SBVAE)的文本特征提取模型，为消除噪声干扰，提高文本将征提取模型的鲁棒性，在文本特征提取的输入层采用双向降噪处理机制。提出一种稀疏平衡性处理，结 KL(Kullback-Leibler)项权重的模拟退火算法以缓解KL算法引发的过度剪枝的影响，强制解码器更充分地利用潜变量。此模型提高了高维数据特征的区分度。从对比分析文本特征提取模型、稀疏性能、稀疏平衡处理对隐藏空间变分下界的影响等方面深入展开实验，验证了该模型具有较好的性能。该模型在复旦数据集和Reuters数据集上的最高准确率相较于主成分分析分别提升了12.36%、8.06%。
研究对象：复旦数据集和Reuters数据集
方法：VAE模型在自然图像和语音生成方面取得了较好的成果，目前在自然语言方面也取得一些进展，许多学者基于VAE对文本领域开展大量研究，文章基于此提出一种SBVAE文本特征提取模型。
步骤1:采用词频-逆文档频率(Term Frequency-Inverse Document Frequency，TF-IDF)算法进行文本表示。
步骤2:针对数据量大、维度高的数据集，为提高数据的特征项明确度和分类精度，采用VAE进行文本特征提取。
步骤3:为提高鲁棒性，采取消除噪声干扰方法，在文本特征提取的输入层采用双向降噪处理机制。
步骤4:为缓解KL散度引发的过度剪枝的影响，并强制解码器更充分地利用潜变量，结合KL项权重的模拟退火算法提出一种稀疏平衡性处理方法。
步骤5:采用文本聚类算法验证文本特征提取的性能。
[2]黄炜,黄建桥,李岳峰.一种基于稀疏自编码器的涉恐短文本特征提取方法[J].情报杂志,2019,38(03):203-207+186.
摘要：【目的/意义】稀疏自编码器是深度学习领域中一种为高效的文本将征提取方法，有利于解决大规模涉恐短文本高维、稀疏难处理等问题。【方法／过程】首先经稀疏自编码器无监督学习方法降维，提取数据隐含特征，然后利用LDA主题聚类算法进行文本聚类，并通过与传统特征提取算法对从实验效果来验证该方法的有效性和高效性。【结果／结论】实验结果证明，将稀疏自编码器提取的文本特征用于LDA主题聚美，有效解决了涉恐短文本高维、稀疏、噪声大的问题，并显著提高了聚类结果的准确性。
研究对象：涉恐短文本
方法：基于稀疏自编码器的涉恐短文本特征提取方法, 其基本思想是利用稀疏自编码器的主动学习过程, 使涉恐短文本由高维向量转化为低维向量, 剔除干扰项, 确保低维向量中包含原始数据的本质特征, 详细过程如图所示。运用涉恐短文本特征提取方法实现对涉恐短文本的特征提取, 过程大体上分为三个部分:对原始数据的预处理过程、稀疏自编码器降维过程及数据本质特征获取过程。
 
实验大体上分两步进行:一是分别采用TF-IDF、信息增益 (IG) 、CHI及互信息算法对实验数据进行文本特征提取, 然后将结果用于LDA主题聚类;二是采用稀疏自编码器处理实验数据, 再将结果用于LDA主题聚类, 最终通过比较实验结果的召回率、准确率和F值, 验证基于稀疏自编码器的涉恐短文本特征提取算法的有效性和高效性。
[3]熊伟,宫禹.基于元学习的不平衡少样本情况下的文本分类研究[J].中文信息学报,2022,36(01):104-116.
摘要:针对文本信息语义、语境迁移难问题，该文提出一种基于元学习与注意力机制模型的动态卷积神经网络改进方法。首先利用文本的底层分布特征进行跨类别分类，使文本信息具有更好的迁移性；其次使用注意力机制对传统的卷积网络进行改进，以提高网络的特征提取能力，并根据原始数据集信息进行编码，生成平衡变量，降低由于数据不平衡所带来的影响；最后使用双层优化的方法使模型自动优化其网络参数。在通用文本分类数据集THUCNews实验结果表明，该文所提出的方法，在1-shot、5-shot情况下，准确率分别提升2.27%、3.26%;在IMDb数据集上，模型准确率分别提升3.28%、3.01%。
对象：少样本文本分类（文中采用的是THUCNews中文文本数据，10个类别）
方法：数据预处理（模拟数据不平衡+数据清洗）
→在训练过程中，学习率采用动态余弦退火学习率，Adam优化器、卷积网络参数借鉴文献 。此外，为了防止训练出现过拟合现象，本文在实验过程中使用了dropout机制和权重正则化限制。
[4]朱良奇,黄勃,黄季涛等.融合BERT和自编码网络的短文本聚类研究[J].计算机工程与应用,2022,58(02):145-152.
摘要:短文本相比于长文本词汇的数量更少，提取其中的语义特征信息更加困难，利用传统的向量空间模型VSM(vector space model)向量化表示，容易得到高维稀疏的向量。词的稀疏表示缺少语义相关性，造成语义鸿沟，从而导致下游聚类任务中，准确率低下，容易受噪声干扰等问题。提出一种新的聚类模型BERT＿AE＿K-Means，利用预训练模型BERT(bidirectional encoder representations from transformers)作为文本表示的初始化方法，利用自动编码器AutoEncoder对文本表示向量进行自训练以提取高阶特征，将得到的特征提取器Encoder和聚类模型K-Means进行联合训练，同时优化特征提取模块和聚类模块，提高聚类模型的准确度和鲁棒性。所提出的模型在四个数据集上与Word2Vec＿K-Means和STC2等6个模型相比，准确率和标准互信息都有所提高，在SearchSnippet数据集上的准确率达到82.28%，实验结果显示，所提方法有效地提高了短文本聚类的准确度。
对象：短文本
（1)SearchSnippets，该数据集来自谷歌搜索引擎，一共有12 295个短文本，包含8个不同类别。（2)StackOverflow，该数据集是一些问答案例的标题数据，发布于Kaggle平台，一共有16 407个短文本，分别来自20个不同类别。（3)BioMedical，该数据集发布于BioASQ官方网站，来自生物医学相关领域，一共包含20个类别和19 448个样本。（4)Tweet，该数据集由2 472个短文本组成，包含89个类别。
方法：本文一共设置了6组对比实验，分别在四个短文本数据集上进行实验，对比模型详细介绍如下：
前两组对比模型是基线模型，分别利用TF-IDF和Word2Vec获取词向量，然后基于词向量对文本进行特征表示，然后直接利用K-Means聚类算法进行聚类。
STC2是一种基于词嵌入和卷积神经网络的短文本聚类算法，在聚类的过程中利用卷积神经网络学习文本表示。
GSDPMM是一种用于短文本聚类的基于狄利克雷过程的多项式混合模型，该模型不需要提前指定簇的个数，由于模型的设计原因，通常趋向于产生更多的簇。
SIF-Auto是一种利用SIF词向量表示方法进行文本表示，然后利用自编码网络进行特征提取，最后进行聚类的算法。
BERT＿K-Means和BERT＿AE＿K-Means两个模型是本文提出的文本表示方法，均采用预训练模型BERT提取文本的语义表示，第一个模型相比第二个没有经过自编码网络进行特征提取和降维，用来验证提取到的高阶特征对下游文本聚类的重要性。
总结：本文提出了一种组合模型用来解决短文本聚类问题，通过利用预训练模型BERT初始化文本向量表征，将文本数据空间转换到特征空间，提取词之间的高维语义关系，然后将得到的文本特征向量输入到自编码网络训练特征映射编码器，通过自编码网络的自监督学习完成编码器Encoder的训练，最后将编码器和聚类模型相结合。利用聚类网络K-Means计算每个样本点的估计概率分布Q和辅助目标分布P，利用KL散度作为损失函数联合训练编码器Encoder和聚类模型。本文的模型在4个公开的数据集上，聚类准确率ACC和标准互信息NMI基本都高于对比实验结果，在数据集SearchSnippet上，通过t-SNE方法对文本数据进行特征降维到2维空间，进行可视化，可以看到本文提出的模型的聚类效果更好，类之间的分割更加明确，本文的研究和提出的模型具有一定的意义。
[5]杨圣豪,吴玥悦,毛佳昕等.基于半监督学习的涉及未成年人案件文书识别方法[J].华南理工大学学报(自然科学版),2021,49(01):29-38+46.
摘要:案件文书作为司法信息公开的重要内容,需要在审判之后向公众公开,某些涉及未成年人的案件文书极有可能会造成未成年人的个人隐私信息泄露。为了能从大量案件文书中准确地识别出涉及未成年人信息的文书,进而有针对性地对其进行隐私保护处理。同时,为解决现实数据集因有标注样本缺乏而难以进行有效的有监督学习的问题,文中提出了基于半监督学习的涉及未成年人案件文书识别方法。首先,对案件文书语料文本进行预处理后分别使用Word2Vec和BERT-wwm-ext对文本进行特征提取,将长语料文本转换为可作为分类模型输入的数据格式;接着,采用PU学习方法训练分类模型,在正例样本极少的情况下借助大量未标注样本构建有效的分类器;然后,在分类模型预测结果的基础上,使用主动学习方法获取关键词并对模型预测结果进行筛选处理,以进一步提升预测效果。在基于现实场景比例构建的测试集上,文中提出的案件文书识别方法取得了98.67%的召回率和81.02%的准确率。
对象：涉及未成年案件文书
方法：文本预处理与特征提取
使用Word2Vec进行文本特征提取，使用BERT进行文本特征提取
→分类模型的训练和预测
使用两个深度学习模型(TextCNN、Text-RCNN)和一个机器学习模型LDA作为分类模型,并采用PU学习方法对分类模型进行训练和预测
→基于主动学习的关键词后处理方法
整个关键词后处理方法基于Libact库实现,同时为便于观察词的权值系数变化情况,本文使用基于词袋模型的特征提取方法,并使用线性分类器进行分类,具体步骤如下:
(1)在有标注训练集上对线性分类器进行训练；
(2)使用训练后的线性分类器对测试集进行预测,记录分类结果的P-R曲线和ROC曲线下面积,并记录分类器对于各个词的权值系数；
(3)使用训练后的线性分类器对未标注数据集进行预测,根据样本选择策略选取待标注样本；
(4)对待标注样本进行标注后加入到有标注训练集中,重新对线性分类器进行训练；
(5)重复步骤(2)、(3)、(4),直到达到可以结束的条件。
 

政策细粒度划分
我的想法是政策细粒度划分有这样两条思路：
1.	按政策本身的自然段进行分割，标以政策编码，通过特征提取→匹配后，溯源到政策本身；
2.	对政策全文进行细分后针对不同标签字段进行合并。

特征匹配
[1]代晓丽,刘世峰,宫大庆.基于NLP的文本相似度检测方法[J].通信学报,2021,42(10):173-181.
摘要：针对当前的文本相似度检测方法忽略文档结构信息、缺乏语义关联性的问题，提出了面向文本的相似度检测方法。首先，采用层次分析法（AHP）计算词语位置权重以提取特征词。其次，引入 Pearson 相关系数度量词语间的语义关联，并将其作为广义 Dice 系数的权重计算相似度。实验表明，所提方法在提高特征词提取的精确度、相似度计算结果的准确率方面表现良好。
对象：
方法：数据提取
→数据预处理
→特征词提取
针对提取的特征词缺乏代表性、相似度计算结果不够准确这2个问题，本文分别提出了基于层次分析法的词语位置加权方法和基于Pearson和广义Dice系数的相似度计算方法。
→词向量生成
→文本相似度计算
→输出结果	
[2]郑新曼,董瑜.基于科技政策文本的程度词典构建研究[J].数据分析与知识发现,2021,5(10):81-93.
摘要：【目的】利用词典法辨识和量化我国科技政策文本用语中蕴含的决策者态度及其强弱程度，解决现有中文政策文本研究忽视词语语义强度的问题。【方法】立足科技政策的功能定位和用语特征，提出程度词的概念。兼顾数量和语义构建程度词典，包括依据专家知识选取种子词，利用PMI算法进行词语扩展，使用同义词词林筛选词语。最后结合TextRank算法进行实验验证。【结果】经信度和效度检验，构建的程度词典有效，结合程度词典的政策文本分析细粒度优于使用单一的文本挖掘算法。【局限】程度词典的权重设计有待细化。【结论】科技政策文本中的程度词丰富、规范且稳定，具有量化分析的价值；词典法可以有效识别并利用程度词，有助于深入挖掘政策文本的语义特征。
对象：中文政策程度词
方法：基于专家知识的种子词选取
→基于词语共现的程度词扩展（点互信息法，PMI）
基于PMI的领域程度词扩展过程如下：
(1)将中文政策文本进行分词、去停用词、词性筛选，得到候选词集。
(2)使用种子词集中的词语word1，将其与候选词集中的词语word2进行关联度计算。
(3)设定关联度阈值t，判断词语的情感倾向。若PMI (word1,word2)>t，则划分word2至程度词集，从而实现对程度词的扩展。
→基于语义相似度的程度词筛选（基于《同义词词林》进行词语间语义相似度的计算）
方法主要分为三步：首先，根据同义词词林中词语义项的编号，计算两词义项的相似度；然后，取这两个词语所有义项相似度的最大值作为这两词的相似度值；最后，确定相似度阈值，筛选出语义相似度较高的词语。相似度取值范围为[0,1]，数值越高，表明两个词语的语义越相似。
 
[3]张文慧,汪美玲,侯志荣.融合语境语义差异特征的短文本匹配模型[J/OL].北京大学学报(自然科学版):1-10[2023-03-06].https://doi.org/10.13209/j.0479-8023.2022.071.
摘要：短文本看是自然语言理解的一个基本研究，由于自然言具有表达歧义性、多样性以及文本本身缺乏上下文的特点，短文本匹配面临字面相同语义不同和字面不同语义相同两大难点。针对该难点，提出一种融台语境语义差异特征的短文本匹配模型。该模型以BERT系列的语言模型作为基础匹配模型，采用一种新的Diff Transformer结构作为差异特征提取器，并以门控方式融合基础语义表示和差异特征表示，以提升匹配效果。模型在中文数据集上达到先进模型的效果。
对象：公开域数据集选择中文问题匹配语料库（LCQMC），是基于海量百度问题构建的问题匹配数据集
方法：
在所有实验中，用Diff来表示构建的模型，设置了2组对比实验和3组消融实验。在对比实验中，横向与相关研究中的基线模型对比实验结果，纵向与不同语言模型融合后对比实验结果。语言模型在超参设置上保持一致，其中学习率设置为2e-05，batch设置为64，epoch设置为3，每1000步保存一次模型，保留效果最好的模型。其余参数通过构建参数矩阵的方式进行动态调整，包括差异特征提取器中Diff Transformer训练的层数k, 差异特征编码器中输入卷积网络的层数f（1<=f<=k）。在消融实验中，设计3个消融变量，分别评估差异分值、词级差异判别和门控融合对实验效果的影响。
[4]金宁,赵春江,吴华瑞等.基于多语义特征的农业短文本匹配技术[J].农业机械学报,2022,53(05):325-331.
摘要：“中国农技推广APP”农业问答社区存在提问数据量大、规范性差、涉及面广、噪声多、特征稀疏等影响文本语义匹配的问题，为了改善农业提问数据相似性判断的性能，提出了融合多语义特征的文本匹配模型Co＿BiLSTM＿CNN,从深度语义、词语共现、最大匹配度3个层面提取短文本特征，并利用共享参数的孪生网络结构，分别运用双向长短期记忆网络、卷积神经网络和密集连接网络构建文本匹配模型。试验结果表明，该模型可以更全面提取文本特征，文本相似性判断的正确率达94.15%,与其他6种模型相比，文本匹配效果优势明显。
对象：试验数据来源于“中国农技推广APP”中的问答社区，共有20 000对问题组合，并通过人工标记的方法，标注了问题组合对中2个问句是否相似。
方法：本文提出的基于多语义特征文本Co_BiLSTM_CNN模型如图1所示。该模型主要由文本预处理层和文本匹配层2部分组成。与一般文本匹配模型相比，本文提出的模型在文本预处理层构建了词语共现关系网，可计算每个词语共现对的权重，进一步丰富了短文本特征；再根据不同文本特征的特点，利用双向长短期记忆网络、卷积神经网络和密集连接网络搭建文本匹配模型，可实现文本特征的多角度提取。
文本预处理
文本分词及词性标注+词向量转换+文本特征增强
→多特征文本匹配模型
孪生网络模型；BiLSTM模型文本特征提取；CNN模型文本特征提取；DNN模型文本特征提取
 
[5]何喜军,马珊,武玉英等.多特征融合下在线技术转移平台供需匹配研究——以京津冀区域数据为例[J].情报杂志,2019,38(06):174-181.（感觉这个可以做复现）
摘要：[目的/意义]为解决在线技术转移平台中因供需信息表述非结构化、供需文本特征稀疏等导致供需文本匹配难的问题,开展线上技术供需信息匹配研究。[方法/过程]提出融合供需文本词频特征、相关性特征和语义特征的匹配模型,通过采集在线技术转移平台(技E网)数据,并针对京津冀技术需求进行供给匹配。[结果/结论]第一,融合多特征的技术供需文本匹配模型,其准确率相比单一特征明显提高;第二,实证研究发现京津冀技术供需文本匹配率为45.437%,但92.5%的供需文本匹配值在0.6左右,匹配值较低,且三地匹配率存在显著差异,河北技术需求在线对接难度更大;第三,技术供需匹配中领域交叉特征不明显,但地理邻近性特征明显。
对象：Python采集“技E网”平台上所有技术项目供给文本和京津冀三个地区的全部技术需求文本, 包括标题、摘要、行业和区域, 对其进行文本预处理、去重、去空筛选, 最终保留在线技术供给文本16455条, 技术需求文本1030条 (其中北京、天津、河北的技术需求分别为429、35、566条)
方法：融合多特征匹配模型的构建流程
构建多特征融合下在线技术供需匹配模型的主要步骤:首先, 采集“技E网”平台的技术供需信息, 包括全网的技术供给文本和京津冀地区的技术需求文本, 进行去重、分词、去停用词等预处理, 得出技术供给和技术需求的关键词集合;然后, 通过基于词向量的语义相似度、TF-IDF模型以及BM25模型分别获取技术供需文本的语义特征、词频特征和相关性特征;其次, 利用熵值法融合多层次特征, 构建技术供需匹配模型;最后, 利用匹配模型筛选出有效供需匹配对并进行模型检验。具体流程如图1所示:
 

政策本身
